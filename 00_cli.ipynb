{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# papersweep\n",
    "\n",
    "> Combining papermill and wandb sweeps for fricitionless experimebnts with Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.all import *\n",
    "import yaml\n",
    "import wandb\n",
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def papersweep_exec(input_nb:Param(\"Input notebook\", str),\n",
    "               sweep_config:Param(\"YAML file with the sweep config\", str), \n",
    "               entity:Param(\"wandb entity\", str), \n",
    "               project:Param(\"wandb project\", str),\n",
    "               pm_params:Param(\"YAML file with papermill parameters\", str)=None,\n",
    "               sweep_id:Param(\"Sweep ID. This option omits `sweep_config`\", str)=None):\n",
    "    with maybe_open(sweep_config, 'r') as f:\n",
    "        sc = yaml.safe_load(f)\n",
    "    if pm_params:\n",
    "        with maybe_open(pm_params, 'r') as f:\n",
    "            rc = yaml.safe_load(f)\n",
    "    sid = wandb.sweep(sweep=sc, entity=entity, project=project) if not sweep_id else sweep_id\n",
    "    sweep_agent = wandb.agent(sid, \n",
    "                              function=partial(pm.execute_notebook,  \n",
    "                                               input_path=input_nb, \n",
    "                                               output_path='__.ipynb', \n",
    "                                               parameters=pm_params))\n",
    "    return sweep_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: be5jqut8\n",
      "Sweep URL: https://wandb.ai/vrodriguezf/papersweep/sweeps/be5jqut8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bce26hgz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch: OmniScaleCNN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b6f16104da469a948162e3c14ad80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ne1po9lq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch: ResNet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a536d7550ed9415788397cf6cf395a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0iiv1kd0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch: LSTM_FCN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2a5e553d564ceda1433ade20fff851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e9d46662 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch: XceptionTime\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a53bdc258cd4e6e9a702ca93ae13d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run e9d46662 errored: PapermillExecutionError('\\n---------------------------------------------------------------------------\\nException encountered at \"In [6]\":\\n---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\n<ipython-input-6-71babf68d27a> in <module>\\n      8 model = create_model(eval(wandb.config.arch), dls=dls, **k)\\n      9 learn = Learner(dls, model, metrics=accuracy)\\n---> 10 learn.fit_one_cycle(25, lr_max=1e-3, cbs=[WandbCallback()])\\n     11 learn.recorder.plot_metrics()\\n\\n~/.local/lib/python3.6/site-packages/fastai/callback/schedule.py in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\\n    110     scheds = {\\'lr\\': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\\n    111               \\'mom\\': combined_cos(pct_start, *(self.moms if moms is None else moms))}\\n--> 112     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)\\n    113 \\n    114 # Cell\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)\\n    203             self.opt.set_hypers(lr=self.lr if lr is None else lr)\\n    204             self.n_epoch = n_epoch\\n--> 205             self._with_events(self._do_fit, \\'fit\\', CancelFitException, self._end_cleanup)\\n    206 \\n    207     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)\\n    152 \\n    153     def _with_events(self, f, event_type, ex, final=noop):\\n--> 154         try:       self(f\\'before_{event_type}\\')       ;f()\\n    155         except ex: self(f\\'after_cancel_{event_type}\\')\\n    156         finally:   self(f\\'after_{event_type}\\')        ;final()\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _do_fit(self)\\n    194         for epoch in range(self.n_epoch):\\n    195             self.epoch=epoch\\n--> 196             self._with_events(self._do_epoch, \\'epoch\\', CancelEpochException)\\n    197 \\n    198     def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)\\n    152 \\n    153     def _with_events(self, f, event_type, ex, final=noop):\\n--> 154         try:       self(f\\'before_{event_type}\\')       ;f()\\n    155         except ex: self(f\\'after_cancel_{event_type}\\')\\n    156         finally:   self(f\\'after_{event_type}\\')        ;final()\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _do_epoch(self)\\n    189     def _do_epoch(self):\\n    190         self._do_epoch_train()\\n--> 191         self._do_epoch_validate()\\n    192 \\n    193     def _do_fit(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _do_epoch_validate(self, ds_idx, dl)\\n    185         if dl is None: dl = self.dls[ds_idx]\\n    186         self.dl = dl\\n--> 187         with torch.no_grad(): self._with_events(self.all_batches, \\'validate\\', CancelValidException)\\n    188 \\n    189     def _do_epoch(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)\\n    152 \\n    153     def _with_events(self, f, event_type, ex, final=noop):\\n--> 154         try:       self(f\\'before_{event_type}\\')       ;f()\\n    155         except ex: self(f\\'after_cancel_{event_type}\\')\\n    156         finally:   self(f\\'after_{event_type}\\')        ;final()\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in all_batches(self)\\n    158     def all_batches(self):\\n    159         self.n_iter = len(self.dl)\\n--> 160         for o in enumerate(self.dl): self.one_batch(*o)\\n    161 \\n    162     def _do_one_batch(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in one_batch(self, i, b)\\n    176         self.iter = i\\n    177         self._split(b)\\n--> 178         self._with_events(self._do_one_batch, \\'batch\\', CancelBatchException)\\n    179 \\n    180     def _do_epoch_train(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)\\n    154         try:       self(f\\'before_{event_type}\\')       ;f()\\n    155         except ex: self(f\\'after_cancel_{event_type}\\')\\n--> 156         finally:   self(f\\'after_{event_type}\\')        ;final()\\n    157 \\n    158     def all_batches(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in __call__(self, event_name)\\n    130     def ordered_cbs(self, event): return [cb for cb in sort_by_run(self.cbs) if hasattr(cb, event)]\\n    131 \\n--> 132     def __call__(self, event_name): L(event_name).map(self._call_one)\\n    133 \\n    134     def _call_one(self, event_name):\\n\\n/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)\\n    177     def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step))\\n    178 \\n--> 179     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))\\n    180     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))\\n    181     def filter(self, f=noop, negate=False, gen=False, **kwargs):\\n\\n/usr/local/lib/python3.6/dist-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs)\\n    604     res = map(g, iterable)\\n    605     if gen: return res\\n--> 606     return list(res)\\n    607 \\n    608 # Cell\\n\\n/usr/local/lib/python3.6/dist-packages/fastcore/basics.py in __call__(self, *args, **kwargs)\\n    594             if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)\\n    595         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]\\n--> 596         return self.func(*fargs, **kwargs)\\n    597 \\n    598 # Cell\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _call_one(self, event_name)\\n    134     def _call_one(self, event_name):\\n    135         assert hasattr(event, event_name), event_name\\n--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]\\n    137 \\n    138     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in <listcomp>(.0)\\n    134     def _call_one(self, event_name):\\n    135         assert hasattr(event, event_name), event_name\\n--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]\\n    137 \\n    138     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)\\n\\n~/.local/lib/python3.6/site-packages/fastai/callback/core.py in __call__(self, event_name)\\n     42                (self.run_valid and not getattr(self, \\'training\\', False)))\\n     43         res = None\\n---> 44         if self.run and _run: res = getattr(self, event_name, noop)()\\n     45         if event_name==\\'after_fit\\': self.run=True #Reset self.run to True at each end of fit\\n     46         return res\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in after_batch(self)\\n    455         if len(self.yb) == 0: return\\n    456         mets = self._train_mets if self.training else self._valid_mets\\n--> 457         for met in mets: met.accumulate(self.learn)\\n    458         if not self.training: return\\n    459         self.lrs.append(self.opt.hypers[-1][\\'lr\\'])\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in accumulate(self, learn)\\n    377     def accumulate(self, learn):\\n    378         bs = find_bs(learn.yb)\\n--> 379         self.total += learn.to_detach(self.func(learn.pred, *learn.yb))*bs\\n    380         self.count += bs\\n    381     @property\\n\\n~/.local/lib/python3.6/site-packages/fastai/metrics.py in accuracy(inp, targ, axis)\\n    100     \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\\n    101     pred,targ = flatten_check(inp.argmax(dim=axis), targ)\\n--> 102     return (pred == targ).float().mean()\\n    103 \\n    104 # Cell\\n\\n~/.local/lib/python3.6/site-packages/torch/tensor.py in wrapped(*args, **kwargs)\\n     23         from torch.overrides import has_torch_function, handle_torch_function\\n     24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\\n---> 25             return handle_torch_function(wrapped, args, *args, **kwargs)\\n     26         try:\\n     27             return f(*args, **kwargs)\\n\\n~/.local/lib/python3.6/site-packages/torch/overrides.py in handle_torch_function(public_api, relevant_args, *args, **kwargs)\\n   1069     raise TypeError(\"no implementation found for \\'{}\\' on types that implement \"\\n   1070                     \\'__torch_function__: {}\\'\\n-> 1071                     .format(func_name, list(map(type, overloaded_args))))\\n   1072 \\n   1073 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\\n\\nTypeError: no implementation found for \\'torch.tensor.eq\\' on types that implement __torch_function__: [<class \\'tsai.data.core.TSTensor\\'>, <class \\'fastai.torch_core.TensorCategory\\'>]\\n',)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run e9d46662 errored: PapermillExecutionError('\\n---------------------------------------------------------------------------\\nException encountered at \"In [6]\":\\n---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\n<ipython-input-6-71babf68d27a> in <module>\\n      8 model = create_model(eval(wandb.config.arch), dls=dls, **k)\\n      9 learn = Learner(dls, model, metrics=accuracy)\\n---> 10 learn.fit_one_cycle(25, lr_max=1e-3, cbs=[WandbCallback()])\\n     11 learn.recorder.plot_metrics()\\n\\n~/.local/lib/python3.6/site-packages/fastai/callback/schedule.py in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\\n    110     scheds = {\\'lr\\': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\\n    111               \\'mom\\': combined_cos(pct_start, *(self.moms if moms is None else moms))}\\n--> 112     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)\\n    113 \\n    114 # Cell\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)\\n    203             self.opt.set_hypers(lr=self.lr if lr is None else lr)\\n    204             self.n_epoch = n_epoch\\n--> 205             self._with_events(self._do_fit, \\'fit\\', CancelFitException, self._end_cleanup)\\n    206 \\n    207     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)\\n    152 \\n    153     def _with_events(self, f, event_type, ex, final=noop):\\n--> 154         try:       self(f\\'before_{event_type}\\')       ;f()\\n    155         except ex: self(f\\'after_cancel_{event_type}\\')\\n    156         finally:   self(f\\'after_{event_type}\\')        ;final()\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _do_fit(self)\\n    194         for epoch in range(self.n_epoch):\\n    195             self.epoch=epoch\\n--> 196             self._with_events(self._do_epoch, \\'epoch\\', CancelEpochException)\\n    197 \\n    198     def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)\\n    152 \\n    153     def _with_events(self, f, event_type, ex, final=noop):\\n--> 154         try:       self(f\\'before_{event_type}\\')       ;f()\\n    155         except ex: self(f\\'after_cancel_{event_type}\\')\\n    156         finally:   self(f\\'after_{event_type}\\')        ;final()\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _do_epoch(self)\\n    189     def _do_epoch(self):\\n    190         self._do_epoch_train()\\n--> 191         self._do_epoch_validate()\\n    192 \\n    193     def _do_fit(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _do_epoch_validate(self, ds_idx, dl)\\n    185         if dl is None: dl = self.dls[ds_idx]\\n    186         self.dl = dl\\n--> 187         with torch.no_grad(): self._with_events(self.all_batches, \\'validate\\', CancelValidException)\\n    188 \\n    189     def _do_epoch(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)\\n    152 \\n    153     def _with_events(self, f, event_type, ex, final=noop):\\n--> 154         try:       self(f\\'before_{event_type}\\')       ;f()\\n    155         except ex: self(f\\'after_cancel_{event_type}\\')\\n    156         finally:   self(f\\'after_{event_type}\\')        ;final()\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in all_batches(self)\\n    158     def all_batches(self):\\n    159         self.n_iter = len(self.dl)\\n--> 160         for o in enumerate(self.dl): self.one_batch(*o)\\n    161 \\n    162     def _do_one_batch(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in one_batch(self, i, b)\\n    176         self.iter = i\\n    177         self._split(b)\\n--> 178         self._with_events(self._do_one_batch, \\'batch\\', CancelBatchException)\\n    179 \\n    180     def _do_epoch_train(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)\\n    154         try:       self(f\\'before_{event_type}\\')       ;f()\\n    155         except ex: self(f\\'after_cancel_{event_type}\\')\\n--> 156         finally:   self(f\\'after_{event_type}\\')        ;final()\\n    157 \\n    158     def all_batches(self):\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in __call__(self, event_name)\\n    130     def ordered_cbs(self, event): return [cb for cb in sort_by_run(self.cbs) if hasattr(cb, event)]\\n    131 \\n--> 132     def __call__(self, event_name): L(event_name).map(self._call_one)\\n    133 \\n    134     def _call_one(self, event_name):\\n\\n/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)\\n    177     def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step))\\n    178 \\n--> 179     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))\\n    180     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))\\n    181     def filter(self, f=noop, negate=False, gen=False, **kwargs):\\n\\n/usr/local/lib/python3.6/dist-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs)\\n    604     res = map(g, iterable)\\n    605     if gen: return res\\n--> 606     return list(res)\\n    607 \\n    608 # Cell\\n\\n/usr/local/lib/python3.6/dist-packages/fastcore/basics.py in __call__(self, *args, **kwargs)\\n    594             if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)\\n    595         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]\\n--> 596         return self.func(*fargs, **kwargs)\\n    597 \\n    598 # Cell\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in _call_one(self, event_name)\\n    134     def _call_one(self, event_name):\\n    135         assert hasattr(event, event_name), event_name\\n--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]\\n    137 \\n    138     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in <listcomp>(.0)\\n    134     def _call_one(self, event_name):\\n    135         assert hasattr(event, event_name), event_name\\n--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]\\n    137 \\n    138     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)\\n\\n~/.local/lib/python3.6/site-packages/fastai/callback/core.py in __call__(self, event_name)\\n     42                (self.run_valid and not getattr(self, \\'training\\', False)))\\n     43         res = None\\n---> 44         if self.run and _run: res = getattr(self, event_name, noop)()\\n     45         if event_name==\\'after_fit\\': self.run=True #Reset self.run to True at each end of fit\\n     46         return res\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in after_batch(self)\\n    455         if len(self.yb) == 0: return\\n    456         mets = self._train_mets if self.training else self._valid_mets\\n--> 457         for met in mets: met.accumulate(self.learn)\\n    458         if not self.training: return\\n    459         self.lrs.append(self.opt.hypers[-1][\\'lr\\'])\\n\\n~/.local/lib/python3.6/site-packages/fastai/learner.py in accumulate(self, learn)\\n    377     def accumulate(self, learn):\\n    378         bs = find_bs(learn.yb)\\n--> 379         self.total += learn.to_detach(self.func(learn.pred, *learn.yb))*bs\\n    380         self.count += bs\\n    381     @property\\n\\n~/.local/lib/python3.6/site-packages/fastai/metrics.py in accuracy(inp, targ, axis)\\n    100     \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\\n    101     pred,targ = flatten_check(inp.argmax(dim=axis), targ)\\n--> 102     return (pred == targ).float().mean()\\n    103 \\n    104 # Cell\\n\\n~/.local/lib/python3.6/site-packages/torch/tensor.py in wrapped(*args, **kwargs)\\n     23         from torch.overrides import has_torch_function, handle_torch_function\\n     24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\\n---> 25             return handle_torch_function(wrapped, args, *args, **kwargs)\\n     26         try:\\n     27             return f(*args, **kwargs)\\n\\n~/.local/lib/python3.6/site-packages/torch/overrides.py in handle_torch_function(public_api, relevant_args, *args, **kwargs)\\n   1069     raise TypeError(\"no implementation found for \\'{}\\' on types that implement \"\\n   1070                     \\'__torch_function__: {}\\'\\n-> 1071                     .format(func_name, list(map(type, overloaded_args))))\\n   1072 \\n   1073 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\\n\\nTypeError: no implementation found for \\'torch.tensor.eq\\' on types that implement __torch_function__: [<class \\'tsai.data.core.TSTensor\\'>, <class \\'fastai.torch_core.TensorCategory\\'>]\\n',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 53bbpvj5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch: ResCNN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9038bd8d07247629cad2a058f432335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i5l5sacb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch: InceptionTime\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241cd1df3b134f139912bc412ba0db16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q7uucjqf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch: xresnet1d34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a95c0dc35e4b42a0b58c13b716120c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "a = papersweep(input_nb='./_example_tsai.ipynb', \n",
    "               sweep_config='examples/sweep_config.yaml', \n",
    "               entity='vrodriguezf', \n",
    "               project='papersweep', \n",
    "               pm_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_cli.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
